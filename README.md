# Web-scraping
# steps in web  scrapping automation 
1.  first you need to install the libraries and packages, this method, i use mainly python script 
2. install selenium and chrome webdriver, and python pandas library 
3. the webdriver script on the file must locate your downloaded webdriver ( path = ""), which depending in your OS system use 
4. execute and run the file accordingly 
5. learn xpath a querry language, html basic structures to expand the writen file on the csv
6. you can costumize the file type which everyou want pdf, csv, xlxs etc.
7. but you need to convert the file into executable to run in one click, to automate the result use a pyinstaller or a auto-py-to-exe
8. after that you need to install crontab and follow the steps on the terminal you can use crontab.guro to modify the time choosen
9. as long as your computer is running everytime the crontab is excuting it will generate the file csv or the data. 
